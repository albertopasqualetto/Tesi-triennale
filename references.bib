
@article{russo_enhancing_nodate,
	title = {Enhancing Preservation and Restoration of Open Reel Audio Tapes Through Computer Vision⋆},
	abstract = {Analog audio documents inevitably face degradation over time, posing a challenge for preserving their audio content and ensuring the integrity of the recordings. Analog document preservation is one of the main research topics of interest of the Centro di Sonologia Computazionale ({CSC}) of the Department of Information Engineering of the University of Padua, which over the years developed and implemented a methodology for preservation that includes, among other things, the video recording of the digitization process of the open-reel tapes for documenting irregularities on the top of their surface. Together with the corpus of digitized high-quality audio recordings, this led to the creation of an internal archive of video documents. This paper presents a software application that leverages computer vision techniques to automatically detect Irregularities on open-reel audio tapes, analyzing the video documents produced during the digitization interventions. The software employs a frame-by-frame analysis to automatically identify and highlight points of interest that may indicate tape damages, splices, and other Irregularities. The software uses Generalized Hough Transform and {SURF} algorithms to locate regions of interest within the tape. The proposed software is also part of the {MPAI}/{IEEE}-{CAE} {ARP} standard developed by Audio Innova s.r.l., spin-off of the {CSC}, and it may offer a robust and efficient solution for analyzing open-reel audio tapes, supporting archivists and musicologists in their activities.},
	author = {Russo, Alessandro and Spanio, Matteo and Canazza, Sergio},
	langid = {english},
	keywords = {da leggere, iniziali, notion},
}

@article{noauthor_guidelines_nodate,
	title = {Guidelines for Digitization Projects for collections and holdings in the public domain},
	langid = {english},
	keywords = {citati, da leggere, notion},
}

@article{orio_methodologies_2009,
	title = {Methodologies and tools for audio digital archives},
	volume = {10},
	issn = {1432-5012, 1432-1300},
	url = {http://link.springer.com/10.1007/s00799-010-0060-6},
	doi = {10.1007/s00799-010-0060-6},
	abstract = {In response to the proposal of digitizing the entire back-run of several European audio archives, many research projects have been carried out in order to discover the technical issues involved in making prestigious audio documents digitally available, which are related to the A/D transfer process and supervised metadata extraction. This article gives an innovative approach to metadata extraction from such a complex source material. This article also describes the protocols deﬁned, the processes undertaken, the results ascertained from several audio documents preservation projects and the techniques used. In addition, a number of recommendations are given for the re-recording process, aimed at minimizing the information loss and to automatically measure the unintentional alterations introduced by the A/D equipment.},
	pages = {201--220},
	number = {4},
	journaltitle = {International Journal on Digital Libraries},
	shortjournal = {Int J Digit Libr},
	author = {Orio, Nicola and Snidaro, Lauro and Canazza, Sergio and Foresti, Gian Luca},
	urldate = {2023-09-07},
	date = {2009-12},
	langid = {english},
	keywords = {citati, da leggere, notion},
}

@collection{international_association_of_sound_and_audiovisual_archives_guidelines_2009,
	location = {Auckland Park, South Africa},
	edition = {2nd edition},
	title = {Guidelines on the production and preservation of digital audio objects: {IASA}-{TC}04},
	isbn = {978-91-976192-3-3 978-91-976192-2-6},
	series = {Standards recommended, practices and strategies},
	shorttitle = {Guidelines on the production and preservation of digital audio objects},
	pagetotal = {150},
	publisher = {International Association of Sound and Audiovisual Archives},
	editor = {International Association of Sound \{and\} Audiovisual Archives and Bradley, Kevin},
	date = {2009},
	langid = {english},
	note = {{OCLC}: ocn318988485},
	keywords = {citati, da leggere, notion},
}

@article{miliano_iasa_nodate,
	title = {The {IASA} Cataloguing Rules ({IASA} 1999)},
	author = {Miliano, Ed Mary},
	langid = {english},
	keywords = {citati, da leggere, notion},
}

@article{canazza_quelle_nodate,
	title = {Quelle voci poco fa: l’intelligenza artiﬁciale a contrastare l’eclisse delle memorie sonore},
	abstract = {Le informazioni acustiche – anche a causa della grande varietà delle tecnologie impiegate, e nonostante il loro continuo perfezionamento –, a differenza di quelle graﬁche, hanno dimostrato di essere estremamente labili, soggette sia a degradazione, sia a possibilità di perdita irreparabile in tempi relativamente brevi. Conservare i supporti originali e, contemporaneamente, l’equipaggiamento necessario alla loro riproduzione è senza speranza: la comunità archivistica internazionale ha introdotto in questo senso lo slogan difendere il contenuto, non il supporto. La conservazione diventa attiva, accogliendo l’idea che è necessario digitalizzare le informazioni acustiche. Procedura complessa, che deve essere svolta da gruppi di ricerca interdisciplinari, possibilmente avvalendosi di strumenti sviluppati nel campo dell’intelligenza artiﬁciale.},
	author = {Canazza, Sergio and Fantozzi, Carlo and Pretto, Niccolò and Rodà, Antonio and Chmiel, Anthony and Schubert, Emery},
	langid = {italian},
	keywords = {che citano, da leggere, notion},
}

@article{bosi_sound_2021,
	title = {Sound and Music Computing using {AI}: Designing a Standard},
	rights = {Creative Commons Attribution 4.0 International, Open Access},
	url = {https://zenodo.org/record/5045003},
	doi = {10.5281/ZENODO.5045003},
	shorttitle = {Sound and Music Computing using {AI}},
	abstract = {While there are currently various approaches that define and adapt the conditions in which the user experiences content or service for several music and audio-related applications including entertainment, communication, audio documents preservation/restoration, we are missing worldwide accepted standards that enable data exchange and interoperability based on common interfaces for such applications. The Moving Picture, Audio and Data Coding by Artificial Intelligence ({MPAI}) is an international non-profit organization whose mission is to develop such standards. Relying on Artificial Intelligence ({AI}), {MPAI} creates a workflow of {AI} Modules ({AIM}) that are interchangeable and upgradable without necessarily changing the logic of the application. A specific area of work, {MPAI} Context-based Audio Enhancement ({MPAI}-{CAE}), is showing tremendous possibilities for the Sound and Music Computing ({SMC}) community. {MPAI}-{CAE} applies context information to the input content to deliver the audio output via the most appropriate protocol. Three {MPAICAE} case studies particularly relevant for the {SMC} community will be presented in this paper: Audio recording preservation ({ARP}), a use case that covers the whole “philologically informed” archival process of an audio document, from the active sound documents preservation to the access to digitized files; Audio-on-the-go ({AOG}), which aims to improve safety and listening quality for situations in which the users are in motion in different environments; and Emotion-enhanced speech ({EES}), a use case that implements a user-friendly system control interface that generates speech with various levels of emotions.},
	author = {Bosi, Marina and Pretto, Niccolò and Guarise, Michelangelo and Canazza, Sergio},
	urldate = {2023-09-07},
	date = {2021-06-30},
	langid = {english},
	note = {Publisher: Zenodo},
	keywords = {che citano, da leggere, notion},
}

@article{chiariglione_ai-based_nodate,
	title = {{AI}-{BASED} {MEDIA} {CODING} {AND} {BEYOND}},
	abstract = {{MPAI} – Moving Picture, Audio and Data Coding by Artificial Intelligence is the first body developing data coding standards that have Artificial Intelligence ({AI}) as its core technology. {MPAI} believes that universally accessible standards for {AI}-based data coding can have the same positive effects on {AI} as standards had on digital media. Elementary components of {MPAI} standards - {AI} Modules ({AIM}) - expose standard interfaces for operation in a standard {AI} Framework ({AIF}). As their performance may depend on the technologies used, {MPAI} expects that competing developers providing {AIMs} will promote horizontal markets of {AI} solutions that build on and further promote {AI} innovation. Finally, the {MPAI} Framework Licences provide guidelines to {IPR} holders facilitating the availability of compatible licences to standard users.},
	author = {Chiariglione, L and Basso, A and Ribeca, P and Bosi, M and Pretto, N and Choi, M and Yassa, F and Iacoviello, R and Artusi, A and Banterle, F and It, Cnr-Isti and Gissi, F and Fiandrotti, A and di, Università and Ballocca, G and Technology, Sisvel and Mazzaglia, M and Rosano, M},
	langid = {english},
	keywords = {da leggere, notion},
}

@article{canazza_four_2019,
	title = {Four Decades of Music Research, Creation, and Education at Padua's Centro di Sonologia Computazionale},
	volume = {43},
	issn = {0148-9267, 1531-5169},
	url = {https://direct.mit.edu/comj/article/43/4/58/97783/Four-Decades-of-Music-Research-Creation-and},
	doi = {10.1162/comj_a_00537},
	abstract = {Research in computer music at the University of Padua, Italy, began in the early 1970s and was formalized in 1979 by establishing the Centro di Sonologia Computazionale ({CSC}). Since its foundation, {CSC} has established itself as a leading research center in the field of computer music. This article describes the scientific and musical research activities of the center and of the composers and members who worked in association with it in its first four decades. The center’s historical background with its musical and scientific precursors is also chronicled, as are important events at {CSC}. An outline of its scientific research activity is then traced, with aspects of the technical details in its different areas of activities, showing the distinctive research ethos and the changing priorities of the center. Research from the 1970s is also included, as it led to the foundation of the {CSC}. Moreover, selected musical works, representative of {CSC} works from historical and scientific points of view, are described. Finally, perspectives for future developments are discussed.},
	pages = {58--80},
	number = {4},
	journaltitle = {Computer Music Journal},
	author = {Canazza, Sergio and Poli, Giovanni De},
	urldate = {2023-09-07},
	date = {2019-12-01},
	langid = {english},
	keywords = {che citano, da leggere, notion},
}

@incollection{russo_linformatica_2019,
	location = {{IT}},
	title = {L’informatica per la gestione e la conservazione di informazioni acustiche (musica e voce)},
	volume = {6},
	isbn = {978-88-97657-38-5},
	url = {https://doi.org/10.17469/O2106AISV000027},
	series = {Studi {AISV}},
	abstract = {The lack of a standard preservation methodology is an important issue that digital speech archives have to face nowadays. Information that needs to be stored requires the implementation of a methodological framework in order to prevent cultural losses. The Centro di Sonologia Computazionale ({CSC}) of the University of Padova, cooperating with several digital archives (both speech and music) implemented a scientific methodology for the active preservation of audio documents. The framework is still a work in progress and the methodology is continuously improved with new additions, such as neural networks and machine learning-based techniques for detecting the right equalization curves or recognizing discontinuities on the tape. This contribution presents the abovementioned methodology, as well as several informatics tools for the study, the access and the preservation of audio documents.},
	pages = {453--464},
	booktitle = {Gli archivi sonori al crocevia tra scienze fonetiche, informatica umanistica e patrimonio digitale},
	publisher = {Officinaventuno},
	author = {Russo, Alessandro and Pretto, Niccolò and Rodà, Antonio and Canazza, Sergio},
	editor = {Piccardi, Duccio and Ardolino, Fabio and Calamai, Silvia},
	urldate = {2023-09-07},
	date = {2019},
	langid = {italian},
	keywords = {che citano, da leggere, notion},
}

@article{pretto_active_2020,
	title = {Active preservation of analogue audio documents: A summary of the last seven years of digitization at {CSC}},
	abstract = {During the last 40 years, a large number of musical works was composed and recorded at the Centro di Sonologia Computazionale ({CSC}) of the University of Padova. The problem of how to preserve this increasing amount of audio documents arose and, in order to meet this need, the {CSC} started to carry out a research to develop a scientiﬁc methodology for preservation. In the last 7 years, this methodology was reﬁned and applied to the digitization of more than 2,500 audio documents both from Italian and international audio archives, mainly stored on analogue magnetic carriers such as open-reel tapes and cassettes. Their content consists of electronic, folk and other kinds of music, as well as speech recordings. The methodology provides for collecting numerous metadata about the original carrier on which the audio information was stored, i.e. ﬂange diameter, brand and material, its physical state and the related preservation copy, necessary for a correct preservation of the content and the contextual information. This work aims to extract and interpret the information from this wealth of data and metadata, which was collected and structured through the software {PSKit}. This may be useful for audio technicians, archives and policy makers to plan future preservation projects.},
	author = {Pretto, Niccolo and Russo, Alessandro and Bressan, Federica and Burini, Valentina and Roda, Antonio and Canazza, Sergio},
	date = {2020},
	langid = {english},
	keywords = {che citano, da leggere, notion},
}

@article{canazza_gesture_2022,
	title = {Gesture, Music and Computer: The Centro di Sonologia Computazionale at Padova University, a 50-Year History},
	volume = {22},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/9/3465},
	doi = {10.3390/s22093465},
	shorttitle = {Gesture, Music and Computer},
	abstract = {With the advent of digital technologies, the computer has become a generalized tool for music production. Music can be seen as a creative form of human–human communication via a computer, and therefore, research on human–computer and computer–human interfaces is very important. This paper, for the Sensors Special Issue on 800 Years of Research at Padova University, presents a review of the research in the ﬁeld of music technologies at Padova University by the Centro di Sonologia Computazionale ({CSC}), focusing on scientiﬁc, technological and musical aspects of interaction between musician and computer and between computer and audience. We discuss input devices for detecting information from gestures or audio signals and rendering systems for audience and user engagement. Moreover, we discuss a multilevel conceptual framework, which allows multimodal expressive content processing and coordination, which is important in art and music. Several paradigmatic musical works that stated new lines of both musical and scientiﬁc research are then presented in detail. The preservation of this heritage presents problems very different from those posed by traditional artworks. {CSC} is actively engaged in proposing new paradigms for the preservation of digital art.},
	pages = {3465},
	number = {9},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Canazza, Sergio and De Poli, Giovanni and Vidolin, Alvise},
	urldate = {2023-09-07},
	date = {2022-05-02},
	langid = {english},
	keywords = {che citano, da leggere, notion},
}

@article{pretto_computing_2018,
	title = {Computing Methodologies Supporting the Preservation of Electroacoustic Music from Analog Magnetic Tape},
	volume = {42},
	issn = {0148-9267, 1531-5169},
	url = {https://direct.mit.edu/comj/article/42/4/59/94833/Computing-Methodologies-Supporting-the},
	doi = {10.1162/comj_a_00487},
	abstract = {Electroacoustic music on analog magnetic tape is characterized by several carrier-related specificities that must be considered when creating a copy for digital preservation. The tape recorder needs to be set to the correct speed and equalization, and the magnetic tape could have some intentional or unintentional alterations. During both the creation and the musicological analysis of a digital preservation copy, the quality of the work may be affected by human inattention. This article presents a methodology based on neural networks to recognize and classify the alterations of a magnetic tape from the video of the tape as it passes in front of the tape recorder’s playback head. Furthermore, some machine-learning techniques have been tested to recognize a tape’s equalization from its background noise. The encouraging results open the way to innovative tools able to unburden audio technicians and musicologists from repetitive tasks and to improve the quality of their work.},
	pages = {59--74},
	number = {4},
	journaltitle = {Computer Music Journal},
	author = {Pretto, Niccoló and Fantozzi, Carlo and Micheloni, Edoardo and Burini, Valentina and Canazza, Sergio},
	urldate = {2023-08-26},
	date = {2018-12-01},
	langid = {english},
	keywords = {iniziali, notion},
}

@misc{spanio_tesi_nodate,
	title = {Tesi Spanio},
	author = {Spanio, Matteo},
	keywords = {iniziali, notion},
}

@article{fantozzi_tape_2017,
	title = {Tape music archives: from preservation to access},
	volume = {18},
	issn = {1432-5012, 1432-1300},
	url = {http://link.springer.com/10.1007/s00799-017-0208-8},
	doi = {10.1007/s00799-017-0208-8},
	shorttitle = {Tape music archives},
	abstract = {This article presents a methodology for the active preservation of, and the access to, magnetic tapes of audio archives. The methodology has been deﬁned and implemented by a multidisciplinary team involving engineers as well as musicians, composers and archivists. The strong point of the methodology is the philological awareness that inﬂuenced the development of digital tools, which consider the critical questions in the historian and musicologist’s approach: the secondary information and the history of transmission of an audio document.},
	pages = {233--249},
	number = {3},
	journaltitle = {International Journal on Digital Libraries},
	shortjournal = {Int J Digit Libr},
	author = {Fantozzi, Carlo and Bressan, Federica and Pretto, Niccolò and Canazza, Sergio},
	urldate = {2023-08-26},
	date = {2017-09},
	langid = {english},
	keywords = {iniziali, notion},
}

@inproceedings{pretto_workflow_2021,
	location = {virtual/Trento Italy},
	title = {A workflow and novel digital filters for compensating speed and equalization errors on digitized audio open-reel tapes},
	isbn = {978-1-4503-8569-5},
	url = {https://dl.acm.org/doi/10.1145/3478384.3478409},
	doi = {10.1145/3478384.3478409},
	abstract = {This paper presents a workflow and novel digital filters for compensating speed and equalization errors that can impact digitized audio open-reel tapes. We examine three frequent cases of mismatch between recording and reproducing standards: {NAB} 3.75 ips - {CCIR} 7.5 ips; {NAB} 3.75 ips - {CCIR} 15 ips; {NAB} 7.5 ips - {CCIR} 15 ips. Three {MUSHRA}-inspired tests ("sets") containing ≥21 participants were used to perceptually assess the workflow and digital filters, using excerpts of music and voice. The results indicated that the digital correction filters performed well, although the electroacoustic stimuli in Set C provided mixed results, suggesting that the style of the music used in perception tests should not be overlooked.},
	eventtitle = {{AM} '21: Audio Mostly 2021},
	pages = {224--231},
	booktitle = {Audio Mostly 2021},
	publisher = {{ACM}},
	author = {Pretto, Niccolò and Dalla Pozza, Nadir and Padoan, Alberto and Chmiel, Anthony and Werner, Kurt James and Micalizzi, Alessandra and Schubert, Emery and Rodà, Antonio and Milani, Simone and Canazza, Sergio},
	urldate = {2023-09-07},
	date = {2021-09},
	langid = {english},
	keywords = {da leggere, notion, ricerche future},
}

@article{raimo_digitalization_2022,
	title = {Digitalization in the cultural industry: evidence from Italian museums},
	volume = {28},
	issn = {1355-2554},
	url = {https://www.emerald.com/insight/content/doi/10.1108/IJEBR-01-2021-0082/full/html},
	doi = {10.1108/IJEBR-01-2021-0082},
	shorttitle = {Digitalization in the cultural industry},
	abstract = {Purpose – This study aims to analyse the level of digitalization in the cultural industry. More in detail, it aims to examine the determinants and effects of the digitalization level of museum organizations and the role played by the {COVID}-19 pandemic in the adoption of digital technologies.},
	pages = {1962--1974},
	number = {8},
	journaltitle = {International Journal of Entrepreneurial Behavior \& Research},
	shortjournal = {{IJEBR}},
	author = {Raimo, Nicola and De Turi, Ivano and Ricciardelli, Alessandra and Vitolla, Filippo},
	urldate = {2023-09-07},
	date = {2022-11-22},
	langid = {english},
	keywords = {da leggere, notion, ricerche future},
}

@article{rakemane_challenges_2021,
	title = {Challenges of managing and preserving audio-visual archives in archival institutions in Sub Saharan Africa: a literature review},
	volume = {40},
	issn = {2514-9326, 2514-9326},
	url = {https://www.emerald.com/insight/content/doi/10.1108/CC-04-2020-0011/full/html},
	doi = {10.1108/CC-04-2020-0011},
	shorttitle = {Challenges of managing and preserving audio-visual archives in archival institutions in Sub Saharan Africa},
	abstract = {Purpose – The purpose of this paper is to identify challenges related to the management and preservation of audio-visual ({AV}) records and/or archives in archival institutions in Sub Saharan Africa and suggests strategies for resolving them. Design/methodology/approach – This study is qualitative in nature and used content analysis from desk top review of literature to identify the challenges and suggested solutions. Findings – Among others, the study revealed that budgetary constraints, poor environmental controls, ill-equipped staff and technological obsolescence are the major challenges hampering the efforts of archival institutions in Sub Saharan Africa to manage and preserve {AV} archives. Research limitations/implications – The contextual differences due to existing political set ups in archival agencies in Sub Saharan Africa may or may not be receptive to some of the strategies suggested for the improvement of managing and preserving audio visual archives. Practical implications – The paper provides practical solutions which can inform policy and practice; thus, if adopted by archival agencies, the ﬁndings can add to improvements in the management and preservation of {AV} records. Originality/value – The study contributes to the body of knowledge on the preservation and management of {AV} archives in the context of Sub Saharan Africa.},
	pages = {42--50},
	number = {2},
	journaltitle = {Collection and Curation},
	shortjournal = {{CC}},
	author = {Rakemane, Donald and Mosweu, Olefhile},
	urldate = {2023-09-07},
	date = {2021-04-08},
	langid = {english},
	keywords = {da leggere, notion, ricerche future},
}

@inproceedings{biswas_audio_2020,
	location = {Barcelona, Spain},
	title = {Audio Codec Enhancement with Generative Adversarial Networks},
	isbn = {978-1-5090-6631-5},
	url = {https://ieeexplore.ieee.org/document/9053113/},
	doi = {10.1109/ICASSP40776.2020.9053113},
	abstract = {Audio codecs are typically transform-domain based and efficiently code stationary audio signals, but they struggle with speech and signals containing dense transient events such as applause. Specifically, with these two classes of signals as examples, we demonstrate a technique for restoring audio from coding noise based on generative adversarial networks ({GAN}). A primary advantage of the proposed {GAN}-based coded audio enhancer is that the method operates end-to-end directly on decoded audio samples, eliminating the need to design any manually-crafted frontend. Furthermore, the enhancement approach described in this paper can improve the sound quality of low-bit rate coded audio without any modifications to the existent standard-compliant encoders. Subjective tests illustrate that the proposed enhancer improves the quality of speech and difficult to code applause excerpts significantly.},
	eventtitle = {{ICASSP} 2020 - 2020 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	pages = {356--360},
	booktitle = {{ICASSP} 2020 - 2020 {IEEE} International Conference on Acoustics, Speech and Signal Processing ({ICASSP})},
	publisher = {{IEEE}},
	author = {Biswas, Arijit and Jia, Dai},
	urldate = {2023-09-07},
	date = {2020-05},
	langid = {english},
	keywords = {da leggere, notion, ricerche future},
}

@article{godsill_4_nodate,
	title = {4 {DIGITAL} {AUDIO} {RESTORATION}},
	abstract = {This chapter is concerned with the application of modern signal processing techniques to the restoration of degraded audio signals. Although attention is focussed on gramophone recordings, film sound tracks and tape recordings, many of the techniques discussed have applications in other areas where degraded audio signals occur, such as speech transmission, telephony and hearing aids. We aim to provide a wide coverage of existing methodology while giving insight into current areas of research and future trends.},
	author = {Godsill, Simon and Rayner, Peter and Cappé, Olivier},
	langid = {english},
	keywords = {da leggere, notion, ricerche future},
}

@report{noauthor_ieee_nodate,
	title = {{IEEE} Standard Adoption of Moving Picture, Audio and Data Coding by Artificial Intelligence ({MPAI}) Technical Specification Context-based Audio Enhanced ({CAE}) Version 1.4},
	url = {https://ieeexplore.ieee.org/document/10112597/},
	abstract = {Abstract: This standard adopts {MPAI} Technical Specification Version 1.4 as an {IEEE} Standard. The Moving Picture, Audio and Data Coding by Artificial Intelligence ({MPAI}) Technical Specification Context-based Audio Enhancement ({CAE}) Version 1.4 is a collection of four use cases specifying {AI}-based technologies for audio-related applications including entertainment, communication, post-production, teleconferencing, and restoration.},
	institution = {{IEEE}},
	urldate = {2023-09-07},
	langid = {english},
	doi = {10.1109/IEEESTD.2023.10112597},
	note = {{ISBN}: 9781504493420},
	keywords = {notion},
}

@report{noauthor_ieee_nodate-1,
	title = {{IEEE} Standard Adoption of Moving Picture, Audio and Data Coding by Artificial Intelligence ({MPAI}) Technical Specification Artificial Intelligence Framework ({AIF}) 1.1},
	url = {https://ieeexplore.ieee.org/document/10112600/},
	abstract = {Abstract: This standard adopts {MPAI} {AI} Framework ({MPAI}-{AIF}) Technical Specification Version 1.1 as an {IEEE} Standard. The {MPAI}-{AIF} Technical Specification specifies architecture, interfaces, protocols, and Application Programming Interfaces ({API}) of an {AI} Framework ({AIF}), especially designed for the execution of {AI}-based implementation, but also suitable for mixed {AI} and traditional data processing workflow.},
	institution = {{IEEE}},
	urldate = {2023-09-07},
	langid = {english},
	doi = {10.1109/IEEESTD.2023.10112600},
	note = {{ISBN}: 9781504493345},
	keywords = {notion},
}

@online{leonardo_new_2020,
	title = {A new way to develop useful standards},
	url = {https://blog.chiariglione.org/a-new-way-to-develop-useful-standards/},
	abstract = {So far, communication standards have been handled in an odd way. Standards are meant to serve the needs of millions, if not billions of people, still the decision about the existence of a standard and what a standard should do is in the hands of people who, no matter how many, are not billions, not […]},
	titleaddon = {Leonardo's Blog},
	author = {{Leonardo}},
	urldate = {2023-09-07},
	date = {2020-11-20},
	langid = {american},
	keywords = {notion},
}

@online{noauthor_mpai_nodate,
	title = {{MPAI} Application Note \#1 Rev. 1},
	url = {https://mpai.community/standards/mpai-cae/mpai-application-note-1-rev-1/},
	abstract = {Context-based Audio Enhancement ({MPAI}-{CAE}) Proponents: Michelangelo Guarise, Andrea Basso ({VOLUMIO})  Description: The overall user experience quality is highly dependent on the context in which audio is used, e.g. Entertainment audio can be consumed in the home, in the car, on public transport, on-the-go (e.g. while doing sports, running, biking) etc. Voice communications: can take place office, […]},
	titleaddon = {{MPAI} community},
	urldate = {2023-09-07},
	langid = {american},
	keywords = {notion},
}

@online{noauthor_about_nodate,
	title = {About {MPAI}-{CAE}},
	url = {https://mpai.community/standards/mpai-cae/about-mpai-cae/},
	abstract = {This is the public page of the Context-based Audio Enhancement ({MPAI}-{CAE}) standard.  See the {MPAI}-{CAE} homepage. Context-based Audio Enhancement ({MPAI}-{CAE}) is a collection of 4 use cases where the user audio experience, including: entertainment, communication, teleconferencing, restoration etc., in a variety of contexts such as in the home, in the car, on-the-go, in the studio […]},
	titleaddon = {{MPAI} community},
	urldate = {2023-09-06},
	langid = {american},
	keywords = {notion},
}

@online{noauthor_mpai_nodate-1,
	title = {Some {MPAI} data coding standards},
	url = {https://mpai.community/some-mpai-data-coding-standards/},
	abstract = {{\textless}–Divide and conquer Structure of {MPAI} standards–{\textgreater} Many experts have participated in the development of {MPAI} data coding standards. In 15 months, {MPAI} has been able to develop three data coding standards: Multimodal Conversation ({MPAI}-{MMC}): 5 use cases Context-based Audio Enhancement ({MPAI}-{CAE}): 4 use cases Compression and Understanding of Industrial Data ({MPAI}-{CUI}): 1 use case […]},
	titleaddon = {{MPAI} community},
	urldate = {2023-09-05},
	langid = {american},
	keywords = {notion},
}

@video{mpaistandards_audio_2023,
	title = {Audio Recording Preservation},
	url = {https://www.youtube.com/watch?v=qtn7vwZVoI4},
	author = {{MPAIstandards}},
	urldate = {2023-09-05},
	date = {2023-04-04},
	keywords = {notion},
}

@online{noauthor_audio_nodate,
	title = {Audio Recording Preservation - {YouTube}},
	url = {https://www.youtube.com/watch?v=qtn7vwZVoI4},
	urldate = {2023-09-05},
	keywords = {notion},
}

@online{noauthor_structure_nodate,
	title = {Structure of {MPAI} standards},
	url = {https://mpai.community/structure-of-mpai-standards/},
	abstract = {{\textless}–Some {MPAI} data coding standards Some technologies from the {MPAI} repository–{\textgreater} {MPAI} produces {AI}-based data coding standards. But what is a “standard”? For sure there is a technical document specifying how things should be done, but {MPAI} adds to this a reference software implementation, normatively equivalent to the technical specification. Then there is a specification […]},
	titleaddon = {{MPAI} community},
	urldate = {2023-09-05},
	langid = {american},
	keywords = {notion},
}

@video{mpaistandards_mpai_2023,
	title = {{MPAI} presents Context-based Audio Enhancement and Reference Software online 2023-07-07},
	url = {https://www.youtube.com/watch?v=32M2Bc5tbI0},
	abstract = {{MPAI} presents Context-based Audio Enhancement and Reference Software online 2023-07-07},
	author = {{MPAIstandards}},
	urldate = {2023-09-05},
	date = {2023-07-10},
	keywords = {notion},
}

@online{noauthor_newsletter-2023-06-14_nodate,
	title = {newsletter-2023-06-14},
	url = {https://mpai.community/newsletter-2023-06-14/},
	abstract = {{MPAI} presents Context-based Audio Enhancement and Reference Software online {MPAI} issues Call for Technologies: {MPAI} Metaverse Model – Architecture     {MPAI} presents Context-based Audio Enhancement and Reference Software online   The Context-based Audio Enhancement standard – {MPAI}-{CAE}/{IEEE} 3302 – improves the user experience for a range of audio-related applications including entertainment, communication, teleconferencing, gaming, […]},
	titleaddon = {{MPAI} community},
	urldate = {2023-09-05},
	langid = {american},
	keywords = {notion},
}

@online{noauthor_mpai-aif_nodate,
	title = {{MPAI}-{AIF} - {MPAI} community},
	url = {https://mpai.community/standards/mpai-aif/},
	abstract = {Artificial Intelligence Framework ({MPAI}-{AIF}) {AI} Framework ({MPAI}-{AIF}) is an {MPAI} standard designed to enable environments ({AIF}) that execute {AI} Workflows ({AIW}) composed of basic components called {AI} Modules ({AIM}). It is a foundational {MPAI} standard on which other {MPAI} application standards are built. The Institute of Electrical and Electronic Engineers ({IEEE}) has adopted {MPAI}-{AIF} with […]},
	titleaddon = {{MPAI} community},
	urldate = {2023-09-04},
	langid = {american},
	keywords = {notion},
}

@online{noauthor_manifesto_nodate,
	title = {Manifesto - {MPAI} community},
	url = {https://mpai.community/about/manifesto/},
	abstract = {Use of technologies based on Artificial Intelligence ({AI}) is extending to more and more applic­ations yielding one of the fastest-grow­ing markets in the data analysis and service sector. However, industry must overcome hurdles for stakeholders to fully exploit this historical oppor­tunity: the current framework-based development model that makes applic­ation redep­loyment difficult, and monolithic and opaque […]},
	titleaddon = {{MPAI} community},
	urldate = {2023-09-04},
	langid = {american},
	keywords = {notion},
}

@online{noauthor_about_nodate-1,
	title = {About - {MPAI} community},
	url = {https://mpai.community/about/},
	abstract = {About Why {MPAI} Statutes Operation How to join Moving Picture, Audio and Data Coding by Artificial Intelligence ({MPAI}) is a Geneva-based international, unaffiliated, not-for-profit organisation with the mission to promote the efficient use of Data by Developing Technical Specifications of Coding any type of Data, e.g. by compression and description, especially using new technologies such […]},
	titleaddon = {{MPAI} community},
	urldate = {2023-09-02},
	langid = {american},
	keywords = {notion},
}
